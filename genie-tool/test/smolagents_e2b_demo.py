#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SmolaAgents E2B Sandbox æ¼”ç¤º

åŸºäºå®˜æ–¹ SmolaAgents æ–‡æ¡£ï¼Œä½¿ç”¨ E2B sandbox è¿›è¡Œå®‰å…¨çš„ä»£ç æ‰§è¡Œã€‚
E2B æä¾›äº†ä¸€ä¸ªéš”ç¦»çš„æ‰§è¡Œç¯å¢ƒï¼Œç¡®ä¿ä»£ç æ‰§è¡Œçš„å®‰å…¨æ€§ã€‚

å®˜æ–¹æ–‡æ¡£: https://github.com/huggingface/smolagents
E2B æ–‡æ¡£: https://e2b.dev/
"""

import os
import asyncio
from typing import Optional, List, Generator, Any

# æ£€æŸ¥å¿…è¦çš„ä¾èµ–
try:
    from smolagents import CodeAgent, LiteLLMModel, InferenceClientModel
    from smolagents import WebSearchTool, FinalAnswerStep, ChatMessageStreamDelta
    print("âœ… smolagents æ ¸å¿ƒç»„ä»¶å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ smolagents å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·å®‰è£…: pip install smolagents")
    exit(1)

try:
    from smolagents.tools import E2BPythonInterpreterTool
    print("âœ… E2B Python è§£é‡Šå™¨å·¥å…·å¯¼å…¥æˆåŠŸ")
except ImportError:
    print("âš ï¸  E2B Python è§£é‡Šå™¨å·¥å…·æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨æ ‡å‡† PythonInterpreterTool")
    try:
        from smolagents import PythonInterpreterTool as E2BPythonInterpreterTool
        print("âœ… ä½¿ç”¨æ ‡å‡† PythonInterpreterTool ä½œä¸ºæ›¿ä»£")
    except ImportError:
        print("âŒ æ— æ³•å¯¼å…¥ Python è§£é‡Šå™¨å·¥å…·")
        exit(1)


class E2BCodeAgent:
    """ä½¿ç”¨ E2B Sandbox çš„å®‰å…¨ä»£ç æ‰§è¡Œæ™ºèƒ½ä½“"""
    
    def __init__(self, 
                 model_type: str = "LiteLLM",
                 model_id: str = "gpt-4o-mini",
                 e2b_api_key: Optional[str] = None,
                 use_web_search: bool = False):
        """
        åˆå§‹åŒ– E2B ä»£ç æ™ºèƒ½ä½“
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ ("LiteLLM", "InferenceClient", "OpenAI")
            model_id: æ¨¡å‹ID
            e2b_api_key: E2B APIå¯†é’¥
            use_web_search: æ˜¯å¦å¯ç”¨ç½‘ç»œæœç´¢åŠŸèƒ½
        """
        self.model_type = model_type
        self.model_id = model_id
        self.e2b_api_key = e2b_api_key or os.getenv("E2B_API_KEY")
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = self._create_model()
        
        # åˆå§‹åŒ–å·¥å…·
        self.tools = self._create_tools(use_web_search)
        
        # åˆ›å»ºä»£ç æ™ºèƒ½ä½“
        self.agent = CodeAgent(
            model=self.model,
            tools=self.tools,
            max_steps=10,
            stream_outputs=True  # å¯ç”¨æµå¼è¾“å‡º
        )
        
        print(f"ğŸ¤– E2B ä»£ç æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ¨¡å‹: {model_type}/{model_id}")
        print(f"   E2B Sandbox: {'âœ… å·²é…ç½®' if self.e2b_api_key else 'âš ï¸  æœªé…ç½®APIå¯†é’¥'}")
        print(f"   å·¥å…·æ•°é‡: {len(self.tools)}")
    
    def _create_model(self):
        """åˆ›å»ºLLMæ¨¡å‹"""
        if self.model_type.lower() == "litellm":
            return LiteLLMModel(
                model_id=self.model_id,
                max_tokens=4000,
                temperature=0.1
            )
        elif self.model_type.lower() == "inferenceclient":
            return InferenceClientModel(
                model_id=self.model_id,
                max_tokens=4000,
                temperature=0.1
            )
        else:
            # é»˜è®¤ä½¿ç”¨ LiteLLM
            return LiteLLMModel(
                model_id=self.model_id,
                max_tokens=4000,
                temperature=0.1
            )
    
    def _create_tools(self, use_web_search: bool = False) -> List:
        """åˆ›å»ºå·¥å…·åˆ—è¡¨"""
        tools = []
        
        # æ·»åŠ  E2B Python è§£é‡Šå™¨å·¥å…·
        try:
            if self.e2b_api_key:
                # ä½¿ç”¨ E2B sandbox
                python_tool = E2BPythonInterpreterTool(
                    api_key=self.e2b_api_key
                )
                print("âœ… ä½¿ç”¨ E2B Sandbox Python è§£é‡Šå™¨")
            else:
                # ä½¿ç”¨æ ‡å‡† Python è§£é‡Šå™¨
                python_tool = E2BPythonInterpreterTool()
                print("âš ï¸  ä½¿ç”¨æ ‡å‡† Python è§£é‡Šå™¨ (å»ºè®®é…ç½® E2B API Key)")
            
            tools.append(python_tool)
        except Exception as e:
            print(f"âŒ Python è§£é‡Šå™¨å·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # æ·»åŠ ç½‘ç»œæœç´¢å·¥å…·
        if use_web_search:
            try:
                web_tool = WebSearchTool()
                tools.append(web_tool)
                print("âœ… ç½‘ç»œæœç´¢å·¥å…·å·²æ·»åŠ ")
            except Exception as e:
                print(f"âš ï¸  ç½‘ç»œæœç´¢å·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}")
        
        return tools
    
    def run_task(self, task: str, stream: bool = True) -> Generator[Any, None, None]:
        """
        æ‰§è¡Œä»»åŠ¡
        
        Args:
            task: ä»»åŠ¡æè¿°
            stream: æ˜¯å¦æµå¼è¾“å‡º
        
        Returns:
            ç”Ÿæˆå™¨ï¼Œé€æ­¥è¿”å›æ‰§è¡Œç»“æœ
        """
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task}")
        print("=" * 60)
        
        try:
            if stream:
                # æµå¼æ‰§è¡Œ
                for step in self.agent.run(task, stream=True):
                    yield step
            else:
                # éæµå¼æ‰§è¡Œ
                result = self.agent.run(task)
                yield result
                
        except Exception as e:
            print(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            raise


class E2BDemoRunner:
    """E2B æ¼”ç¤ºè¿è¡Œå™¨"""
    
    def __init__(self):
        self.agent = None
    
    def check_environment(self) -> bool:
        """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
        print("ğŸ” æ£€æŸ¥ç¯å¢ƒé…ç½®...")
        
        # æ£€æŸ¥ LLM API å¯†é’¥
        llm_key_found = False
        if os.getenv("OPENAI_API_KEY"):
            print("âœ… OPENAI_API_KEY å·²é…ç½®")
            llm_key_found = True
        if os.getenv("DEEPSEEK_API_KEY"):
            print("âœ… DEEPSEEK_API_KEY å·²é…ç½®")
            llm_key_found = True
        if os.getenv("ANTHROPIC_API_KEY"):
            print("âœ… ANTHROPIC_API_KEY å·²é…ç½®")
            llm_key_found = True
            
        if not llm_key_found:
            print("âš ï¸  æœªæ£€æµ‹åˆ° LLM API å¯†é’¥")
            print("   è¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ä¹‹ä¸€:")
            print("   export OPENAI_API_KEY='your-key'")
            print("   export DEEPSEEK_API_KEY='your-key'")
            print("   export ANTHROPIC_API_KEY='your-key'")
        
        # æ£€æŸ¥ E2B API å¯†é’¥
        if os.getenv("E2B_API_KEY"):
            print("âœ… E2B_API_KEY å·²é…ç½®")
        else:
            print("âš ï¸  E2B_API_KEY æœªé…ç½®")
            print("   è®¿é—® https://e2b.dev/ è·å–å…è´¹APIå¯†é’¥")
            print("   export E2B_API_KEY='your-e2b-key'")
        
        print("âœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆ")
        return True
    
    async def run_demo(self):
        """è¿è¡Œæ¼”ç¤º"""
        print("ğŸ¯ SmolaAgents E2B Sandbox æ¼”ç¤º")
        print("åŸºäºå®˜æ–¹æ–‡æ¡£: https://github.com/huggingface/smolagents")
        print("=" * 60)
        
        if not self.check_environment():
            return
        
        # åˆ›å»ºæ™ºèƒ½ä½“
        print("\nğŸ¤– åˆ›å»º E2B ä»£ç æ™ºèƒ½ä½“...")
        self.agent = E2BCodeAgent(
            model_type="LiteLLM",
            model_id="gpt-4o-mini",
            use_web_search=True
        )
        
        # è¿è¡Œæ¼”ç¤ºä»»åŠ¡
        await self._run_demo_tasks()
    
    async def _run_demo_tasks(self):
        """è¿è¡Œæ¼”ç¤ºä»»åŠ¡"""
        
        demo_tasks = [
            {
                "name": "æ•°æ®ç§‘å­¦åˆ†æ",
                "task": """
                åˆ›å»ºä¸€ä¸ªæ•°æ®ç§‘å­¦åˆ†æï¼š
                1. ç”Ÿæˆä¸€ä¸ªåŒ…å«100ä¸ªæ•°æ®ç‚¹çš„éšæœºæ•°æ®é›†ï¼ˆåŒ…å«å¹´é¾„ã€æ”¶å…¥ã€æ•™è‚²æ°´å¹³ï¼‰
                2. è¿›è¡ŒåŸºç¡€ç»Ÿè®¡åˆ†æ
                3. åˆ›å»ºç›¸å…³æ€§åˆ†æ
                4. ç»˜åˆ¶æ•°æ®å¯è§†åŒ–å›¾è¡¨
                5. æ€»ç»“åˆ†æç»“æœ
                """
            },
            {
                "name": "æœºå™¨å­¦ä¹ æ¼”ç¤º",
                "task": """
                åˆ›å»ºä¸€ä¸ªç®€å•çš„æœºå™¨å­¦ä¹ æ¼”ç¤ºï¼š
                1. ä½¿ç”¨ sklearn ç”Ÿæˆåˆ†ç±»æ•°æ®é›†
                2. è®­ç»ƒä¸€ä¸ªç®€å•çš„åˆ†ç±»æ¨¡å‹
                3. è¯„ä¼°æ¨¡å‹æ€§èƒ½
                4. ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
                5. è§£é‡Šç»“æœ
                """
            },
            {
                "name": "ç½‘ç»œæ•°æ®åˆ†æ",
                "task": """
                è¿›è¡Œç½‘ç»œæ•°æ®åˆ†æï¼š
                1. æœç´¢æœ€æ–°çš„ Python ç¼–ç¨‹è¶‹åŠ¿
                2. åˆ†ææœç´¢ç»“æœ
                3. åˆ›å»ºä¸€ä¸ªç®€å•çš„æ•°æ®å¯è§†åŒ–
                4. æ€»ç»“å‘ç°çš„è¶‹åŠ¿
                """
            }
        ]
        
        for i, demo in enumerate(demo_tasks, 1):
            print(f"\nğŸ“‹ æ¼”ç¤º {i}: {demo['name']}")
            print("-" * 50)
            
            try:
                step_count = 0
                for step in self.agent.run_task(demo['task'], stream=True):
                    step_count += 1
                    self._handle_step_output(step, step_count)
                    
                    # å¼‚æ­¥è®©å‡ºæ§åˆ¶æƒ
                    await asyncio.sleep(0.1)
                    
            except Exception as e:
                print(f"âŒ æ¼”ç¤º {i} æ‰§è¡Œå¤±è´¥: {e}")
            
            # è¯¢é—®æ˜¯å¦ç»§ç»­
            if i < len(demo_tasks):
                print("\n" + "="*60)
                choice = input("æŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€ä¸ªæ¼”ç¤ºï¼Œæˆ–è¾“å…¥ 'q' é€€å‡º: ").strip()
                if choice.lower() == 'q':
                    break
    
    def _handle_step_output(self, step, step_num: int):
        """å¤„ç†æ­¥éª¤è¾“å‡º"""
        if isinstance(step, FinalAnswerStep):
            print(f"\nğŸ‰ æœ€ç»ˆç­”æ¡ˆ:")
            print("-" * 30)
            print(step.output)
        elif isinstance(step, ChatMessageStreamDelta):
            if step.content:
                print(step.content, end='', flush=True)
        else:
            # å…¶ä»–ç±»å‹çš„æ­¥éª¤
            print(f"\nğŸ“ æ­¥éª¤ {step_num}: {type(step).__name__}")
            if hasattr(step, 'output') and step.output:
                print(f"   è¾“å‡º: {step.output[:100]}...")


async def interactive_mode():
    """äº¤äº’æ¨¡å¼"""
    print("\nğŸ® E2B Sandbox äº¤äº’æ¨¡å¼")
    print("è¾“å…¥ä»»åŠ¡æè¿°ï¼Œæ™ºèƒ½ä½“å°†åœ¨å®‰å…¨çš„ E2B ç¯å¢ƒä¸­æ‰§è¡Œä»£ç ")
    print("è¾“å…¥ 'quit' é€€å‡º")
    print("-" * 50)
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = E2BCodeAgent(
        model_type="LiteLLM",
        model_id="gpt-4o-mini",
        use_web_search=True
    )
    
    while True:
        task = input("\nğŸ’¬ è¯·è¾“å…¥ä»»åŠ¡: ").strip()
        
        if task.lower() in ['quit', 'exit', 'q']:
            print("ğŸ‘‹ é€€å‡ºäº¤äº’æ¨¡å¼")
            break
        
        if not task:
            continue
        
        try:
            print(f"\nğŸš€ æ‰§è¡Œä»»åŠ¡: {task}")
            print("-" * 40)
            
            step_count = 0
            for step in agent.run_task(task, stream=True):
                step_count += 1
                
                if isinstance(step, FinalAnswerStep):
                    print(f"\nâœ… æœ€ç»ˆç»“æœ:")
                    print(step.output)
                elif isinstance(step, ChatMessageStreamDelta):
                    if step.content:
                        print(step.content, end='', flush=True)
                else:
                    print(f"\nğŸ“ æ­¥éª¤ {step_count}: {type(step).__name__}")
                
                # å¼‚æ­¥è®©å‡ºæ§åˆ¶æƒ
                await asyncio.sleep(0.05)
                
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå‡ºé”™: {e}")


def print_usage():
    """æ‰“å°ä½¿ç”¨è¯´æ˜"""
    print("""
ğŸ¯ SmolaAgents E2B Sandbox æ¼”ç¤º

åŸºäºå®˜æ–¹æ–‡æ¡£: https://github.com/huggingface/smolagents

ä½¿ç”¨æ–¹æ³•:
    python smolagents_e2b_demo.py [æ¨¡å¼]

æ¨¡å¼é€‰é¡¹:
    demo        - å®Œæ•´æ¼”ç¤ºï¼ˆé»˜è®¤ï¼‰
    interactive - äº¤äº’æ¨¡å¼
    help        - æ˜¾ç¤ºå¸®åŠ©

ç¯å¢ƒè¦æ±‚:
    - Python 3.8+
    - smolagents åŒ…
    - LLM APIå¯†é’¥ (OpenAI/DeepSeek/Anthropic)
    - E2B APIå¯†é’¥ (å¯é€‰ï¼Œç”¨äºå®‰å…¨æ²™ç®±)

ç¯å¢ƒå˜é‡:
    # LLM API (é€‰æ‹©å…¶ä¸€)
    export OPENAI_API_KEY='your-openai-key'
    export DEEPSEEK_API_KEY='your-deepseek-key'
    export ANTHROPIC_API_KEY='your-anthropic-key'
    
    # E2B Sandbox (å¯é€‰)
    export E2B_API_KEY='your-e2b-key'

E2B å®‰å…¨ç‰¹æ€§:
    - å®Œå…¨éš”ç¦»çš„æ‰§è¡Œç¯å¢ƒ
    - é˜²æ­¢æ¶æ„ä»£ç å½±å“ä¸»æœºç³»ç»Ÿ
    - æ”¯æŒç½‘ç»œè®¿é—®å’Œæ–‡ä»¶æ“ä½œ
    - è‡ªåŠ¨èµ„æºæ¸…ç†

ç¤ºä¾‹:
    python smolagents_e2b_demo.py demo
    python smolagents_e2b_demo.py interactive
    """)


async def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    mode = sys.argv[1] if len(sys.argv) > 1 else "demo"
    
    if mode in ["help", "-h", "--help"]:
        print_usage()
        return
    
    print("ğŸš€ å¯åŠ¨ SmolaAgents E2B Sandbox æ¼”ç¤ºç¨‹åº...")
    print("åŸºäºå®˜æ–¹æ–‡æ¡£: https://github.com/huggingface/smolagents")
    
    try:
        if mode == "demo":
            runner = E2BDemoRunner()
            await runner.run_demo()
        elif mode == "interactive":
            await interactive_mode()
        else:
            print(f"âŒ æœªçŸ¥æ¨¡å¼: {mode}")
            print_usage()
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print("ğŸ® SmolaAgents E2B Sandbox æ¼”ç¤º")
    print("å®‰å…¨çš„ä»£ç æ‰§è¡Œç¯å¢ƒ + å¼ºå¤§çš„AIæ™ºèƒ½ä½“")
    print("=" * 60)
    
    try:
        asyncio.run(main())
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥ä¾èµ–å®‰è£…å’Œç¯å¢ƒé…ç½®")
